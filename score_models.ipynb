{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the librarys\n",
    "import pandas as pd #To work with dataset\n",
    "import numpy as np #Math library\n",
    "import seaborn as sns #Graph library that use matplot in background\n",
    "import matplotlib.pyplot as plt #to plot some parameters in seaborn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion();\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy import linalg\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report , confusion_matrix , accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from triedpy import triedctk   as ctk\n",
    "from triedpy import triedsompy as SOM\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.cluster.hierarchy as sch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'exo4' from 'C:\\\\Users\\\\HP\\\\Anaconda3\\\\Scripts\\\\Project_DQ\\\\credit_bank_estimation\\\\exo4.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib as im\n",
    "import exo4\n",
    "im.reload(exo4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster import hierarchy\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn import preprocessing, model_selection, metrics, feature_selection\n",
    "from sklearn import (manifold, datasets, decomposition, ensemble,\n",
    "                     discriminant_analysis, random_projection)\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I . Data Entry "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv(\"german_credit_data_risk.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'Sex',\n",
       " 'Job',\n",
       " 'Housing',\n",
       " 'Saving accounts',\n",
       " 'Checking account',\n",
       " 'Credit amount',\n",
       " 'Duration',\n",
       " 'Purpose',\n",
       " 'Risk']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Job</th>\n",
       "      <th>Credit amount</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.546000</td>\n",
       "      <td>1.904000</td>\n",
       "      <td>3271.258000</td>\n",
       "      <td>20.903000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.375469</td>\n",
       "      <td>0.653614</td>\n",
       "      <td>2822.736876</td>\n",
       "      <td>12.058814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>12.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2319.500000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3972.250000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18424.000000</td>\n",
       "      <td>72.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Age          Job  Credit amount     Duration\n",
       "count  1000.000000  1000.000000    1000.000000  1000.000000\n",
       "mean     35.546000     1.904000    3271.258000    20.903000\n",
       "std      11.375469     0.653614    2822.736876    12.058814\n",
       "min      19.000000     0.000000     250.000000     4.000000\n",
       "25%      27.000000     2.000000    1365.500000    12.000000\n",
       "50%      33.000000     2.000000    2319.500000    18.000000\n",
       "75%      42.000000     2.000000    3972.250000    24.000000\n",
       "max      75.000000     3.000000   18424.000000    72.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_credit = df_credit.fillna('unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_ranges      = [list(range(15 + 5*i,15 + 5*i+5)) for i in range(12)]\n",
    "duration_ranges = [list(range(5*i,5*i+5)) for i in range(14)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ages = (df_credit['Age'].unique()).tolist()\n",
    "sexes = (df_credit['Sex'].unique()).tolist()\n",
    "jobs = (df_credit['Job'].unique()).tolist()\n",
    "housings = (df_credit['Housing'].unique()).tolist()\n",
    "save_account = (df_credit['Saving accounts'].unique()).tolist()\n",
    "check_account = (df_credit['Checking account'].unique()).tolist()\n",
    "credit_amounts = (df_credit['Credit amount'].unique()).tolist()\n",
    "durations = (df_credit['Duration'].unique()).tolist()\n",
    "purposes = (df_credit['Purpose'].unique()).tolist()\n",
    "risks = (df_credit['Risk'].unique()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2888.0675629490124\n"
     ]
    }
   ],
   "source": [
    "st = np.std(np.array(credit_amounts)) ; print(st)\n",
    "mx = np.max(np.array(credit_amounts))\n",
    "mean =  np.mean(np.array(credit_amounts))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "enc_age = []\n",
    "enc_sex = []\n",
    "enc_job = []\n",
    "enc_house = []\n",
    "enc_save = []\n",
    "enc_check = []\n",
    "enc_credit = []\n",
    "enc_duration = []\n",
    "enc_purpo = []\n",
    "enc_risk = []\n",
    "for idx in range(len(df_credit)):\n",
    "    ##--------------\n",
    "    a = df_credit.iloc[idx]['Age']\n",
    "    vect = np.zeros((len(age_ranges,)))\n",
    "    for j in range(len(age_ranges)):\n",
    "        if a in age_ranges[j]:\n",
    "            vect[j] = 1\n",
    "            break\n",
    "    enc_age.append(vect)\n",
    "    \n",
    "    ##-------------\n",
    "    a = df_credit.iloc[idx]['Sex']\n",
    "    vect = np.zeros((len(sexes,)))\n",
    "    ind = sexes.index(a)\n",
    "    vect[ind] = 1\n",
    "    enc_sex.append(vect)\n",
    "    ##------------\n",
    "    a = df_credit.iloc[idx]['Job']\n",
    "    vect = np.zeros((len(jobs,)))\n",
    "    ind = jobs.index(a)\n",
    "    vect[ind] = 1\n",
    "    enc_job.append(vect)\n",
    "    ## -----------\n",
    "    a = df_credit.iloc[idx]['Housing']\n",
    "    vect = np.zeros((len(housings,)))\n",
    "    ind = housings.index(a)\n",
    "    vect[ind] = 1\n",
    "    enc_house.append(vect)\n",
    "    ##____________\n",
    "    a = df_credit.iloc[idx]['Saving accounts']\n",
    "    vect = np.zeros((len(save_account,)))\n",
    "    ind = save_account.index(a)\n",
    "    vect[ind] = 1\n",
    "    enc_save.append(vect)\n",
    "    ##_____________\n",
    "    a = df_credit.iloc[idx]['Checking account']\n",
    "    vect = np.zeros((len(check_account,)))\n",
    "    ind = check_account.index(a)\n",
    "    vect[ind] = 1\n",
    "    enc_check.append(vect)\n",
    "    ##____________\n",
    "    a = df_credit.iloc[idx]['Credit amount']\n",
    "    #vect = np.zeros((len(credit_amounts,)))\n",
    "    #ind = credit_amounts.index(a)\n",
    "    #vect[ind] = 1\n",
    "    centred = a/mx #(a - mean)/st\n",
    "    enc_credit.append(centred)\n",
    "    ## ___________\n",
    "    \n",
    "    a = df_credit.iloc[idx]['Duration']\n",
    "    vect = np.zeros((len(duration_ranges,)))\n",
    "    for j in range(len(duration_ranges)):\n",
    "        if a in duration_ranges[j]:\n",
    "            vect[j] = 1\n",
    "            break\n",
    "    enc_duration.append(vect)\n",
    "    ##_____________\n",
    "    a = df_credit.iloc[idx]['Purpose']\n",
    "    vect = np.zeros((len(purposes,)))\n",
    "    ind = purposes.index(a)\n",
    "    vect[ind] = 1\n",
    "    enc_purpo.append(vect)\n",
    "    ##____________\n",
    "    a = df_credit.iloc[idx]['Risk']\n",
    "    vect = np.zeros((len(risks,)))\n",
    "    ind = risks.index(a)\n",
    "    vect[ind] = 1\n",
    "    enc_risk.append(vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_age = np.array(enc_age)\n",
    "enc_sex = np.array(enc_sex)\n",
    "enc_job = np.array(enc_job)\n",
    "enc_house = np.array(enc_house)\n",
    "enc_save = np.array(enc_save)\n",
    "enc_check = np.array(enc_check)\n",
    "enc_credit = np.array(enc_credit)\n",
    "enc_duration = np.array(enc_duration)\n",
    "enc_purpo = np.array(enc_purpo)\n",
    "enc_risk = np.array(enc_risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "risk = np.array([np.argmax(r) for r in enc_risk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = np.concatenate((enc_age,enc_sex,enc_job,enc_house,enc_save,enc_check,enc_credit.reshape((-1,1)),enc_duration,enc_purpo),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = decomposition.PCA()\n",
    "pca.fit(X_all)\n",
    "pca_samples = pca.transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "sns.set(font_scale=1)\n",
    "plt.step(range(X_all.shape[1]), pca.explained_variance_ratio_.cumsum(), where='mid',\n",
    "         label='cumulative explained variance')\n",
    "sns.barplot(np.arange(1,X_all.shape[1]+1), pca.explained_variance_ratio_, alpha=0.5, color = 'g',\n",
    "            label='individual explained variance')\n",
    "plt.xlim(0, 100)\n",
    "\n",
    "ax.set_xticklabels([s if int(s.get_text())%2 == 0 else '' for s in ax.get_xticklabels()])\n",
    "\n",
    "plt.ylabel('Explained variance', fontsize = 14)\n",
    "plt.xlabel('Principal components', fontsize = 14)\n",
    "plt.legend(loc='upper left', fontsize = 13);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "pca = decomposition.PCA(2)\n",
    "pca.fit(X_all)\n",
    "pca_samples = pca.transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FastICA \n",
    "ICA = FastICA(n_components=30, random_state=0, tol = 0.01) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ICA = ICA.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hasher = ensemble.RandomTreesEmbedding(n_estimators=200, random_state=0,max_depth=5)\n",
    "X_transformed = hasher.fit_transform(X_all)\n",
    "pca = decomposition.TruncatedSVD(30) # Truncated\n",
    "X_reduced = pca.fit_transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'isomap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-f19be2a14636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_red_iso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misomap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_transformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'isomap' is not defined"
     ]
    }
   ],
   "source": [
    "X_red_iso = isomap.fit_transform(X_transformed.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = []\n",
    "for l in enc_risk:\n",
    "    if(l[0] == 1):\n",
    "        colors.append('blue')\n",
    "    else:\n",
    "        colors.append('red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isomap = manifold.Isomap(n_neighbors=6, n_components=30)\n",
    "X_isomap = isomap.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ran = np.array(range(1000))\n",
    "ran_train , ran_test = train_test_split(ran,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_iso , X_test_iso , X_train_ica , X_test_ica, r_train , r_test = X_isomap[ran_train] ,X_isomap[ran_test], \\\n",
    "    X_ICA[ran_train] , X_ICA[ran_test] , enc_risk[ran_train] , enc_risk[ran_test]\n",
    "X_train_pca , X_test_pca = X_reduced[ran_train] ,X_reduced[ran_test]\n",
    "risk1 = [np.argmax(x) for x in r_train]\n",
    "risk2 = [np.argmax(x) for x in r_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M1 = Sequential()\n",
    "M1.add(Dense(30,input_shape= (30,)))\n",
    "M1.add(Activation('relu'))\n",
    "M1.add(Dense(30))\n",
    "M1.add(Activation('relu'))\n",
    "M1.add(Dense(2))\n",
    "M1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M1.compile(optimizer='adamax',loss='categorical_crossentropy',metrics = ['accuracy']) # categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.3101 - acc: 0.8771 - val_loss: 0.6812 - val_acc: 0.6733\n",
      "Epoch 2/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.2967 - acc: 0.8814 - val_loss: 0.6441 - val_acc: 0.7167\n",
      "Epoch 3/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.2907 - acc: 0.8871 - val_loss: 0.6756 - val_acc: 0.6833\n",
      "Epoch 4/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.2799 - acc: 0.8900 - val_loss: 0.6763 - val_acc: 0.6967\n",
      "Epoch 5/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.2737 - acc: 0.8971 - val_loss: 0.6850 - val_acc: 0.7100\n",
      "Epoch 6/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.2635 - acc: 0.9057 - val_loss: 0.7135 - val_acc: 0.6967\n",
      "Epoch 7/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.2579 - acc: 0.9000 - val_loss: 0.7059 - val_acc: 0.7200\n",
      "Epoch 8/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.2458 - acc: 0.9143 - val_loss: 0.7283 - val_acc: 0.6933\n",
      "Epoch 9/10\n",
      "700/700 [==============================] - 1s 2ms/step - loss: 0.2409 - acc: 0.9057 - val_loss: 0.7482 - val_acc: 0.6900\n",
      "Epoch 10/10\n",
      "700/700 [==============================] - 1s 1ms/step - loss: 0.2318 - acc: 0.9157 - val_loss: 0.7334 - val_acc: 0.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179aed01a58>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M1.fit(X_train_pca,r_train,epochs = 10, batch_size = 2,validation_data = (X_test_pca,r_test) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_pred_1 = M1.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r_pred_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-4272ebbf9843>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_pred_1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r_pred_1' is not defined"
     ]
    }
   ],
   "source": [
    "labels = [np.argmax(l) for l in r_pred]\n",
    "orig = [np.argmax(l) for l in r_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.7066666666666667\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.83      0.80       214\n",
      "          1       0.49      0.41      0.44        86\n",
      "\n",
      "avg / total       0.69      0.71      0.70       300\n",
      "\n",
      "Conf. Matrix \n",
      " [[177  37]\n",
      " [ 51  35]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score\",accuracy_score(risk2,labels))\n",
    "print(\"Classification Report\",classification_report(risk2,labels))\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.6766666666666666\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.78      0.77       213\n",
      "          1       0.44      0.41      0.43        87\n",
      "\n",
      "avg / total       0.67      0.68      0.67       300\n",
      "\n",
      "Conf. Matrix \n",
      " [[167  46]\n",
      " [ 51  36]]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=None, max_features=X_train_pca.shape[1], n_estimators=15, random_state=2)\n",
    "rf.fit(X_train_pca,risk1)\n",
    "r_rf = rf.predict(X_test_pca)\n",
    "print(\"Accuracy Score\",accuracy_score(risk2,r_rf))\n",
    "print(\"Classification Report\",classification_report(risk2,r_rf))\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_iso,risk1)\n",
    "r_tree = tree.predict(X_test_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.6266666666666667\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.72      0.73       213\n",
      "          1       0.37      0.40      0.38        87\n",
      "\n",
      "avg / total       0.64      0.63      0.63       300\n",
      "\n",
      "Conf. Matrix \n",
      " [[153  60]\n",
      " [ 52  35]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score\",accuracy_score(risk2,r_tree))\n",
    "print(\"Classification Report\",classification_report(risk2,r_tree))\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian \n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB = GaussianNB()\n",
    "NB.fit(X_train_iso,risk1)\n",
    "r_nb = NB.predict(X_test_iso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.7066666666666667\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.78      0.82      0.80       213\n",
      "          1       0.49      0.44      0.46        87\n",
      "\n",
      "avg / total       0.70      0.71      0.70       300\n",
      "\n",
      "Conf. Matrix \n",
      " [[174  39]\n",
      " [ 49  38]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score\",accuracy_score(risk2,r_nb))\n",
    "print(\"Classification Report\",classification_report(risk2,r_nb))\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.69\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.80      0.79       213\n",
      "          1       0.46      0.43      0.44        87\n",
      "\n",
      "avg / total       0.68      0.69      0.69       300\n",
      "\n",
      "Conf. Matrix \n",
      " [[170  43]\n",
      " [ 50  37]]\n"
     ]
    }
   ],
   "source": [
    "clf = discriminant_analysis.LinearDiscriminantAnalysis()\n",
    "clf.fit(X_train_ica, risk1) # Quadratic\n",
    "r_lda = clf.predict(X_test_ica)\n",
    "print(\"Accuracy Score\",accuracy_score(risk2,r_lda))\n",
    "print(\"Classification Report\",classification_report(risk2,r_lda))\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clfq = discriminant_analysis.QuadraticDiscriminantAnalysis().fit(X_train_ica, risk1) \n",
    "r_qda = clfq.predict(X_test_ica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.6333333333333333\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.65      0.72       213\n",
      "          1       0.41      0.59      0.48        87\n",
      "\n",
      "avg / total       0.68      0.63      0.65       300\n",
      "\n",
      "Conf. Matrix \n",
      " [[139  74]\n",
      " [ 36  51]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score\",accuracy_score(risk2,r_qda))\n",
    "print(\"Classification Report\",classification_report(risk2,r_qda))\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_qda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.6933333333333334 \n",
      " ----------------\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.85      0.80       213\n",
      "          1       0.46      0.30      0.36        87\n",
      "\n",
      "avg / total       0.66      0.69      0.67       300\n",
      " \n",
      " ----------------\n",
      "Conf. Matrix \n",
      " [[182  31]\n",
      " [ 61  26]] \n",
      " ----------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_iso,risk1)\n",
    "r_xgb = xgb.predict(X_test_iso)\n",
    "print(\"Accuracy Score\",accuracy_score(risk2,r_xgb),\"\\n ----------------\")\n",
    "print(\"Classification Report \\n\",classification_report(risk2,r_xgb),\"\\n ----------------\")\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_xgb),\"\\n ----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.7433333333333333 \n",
      " ----------------\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.92      0.84       213\n",
      "          1       0.61      0.31      0.41        87\n",
      "\n",
      "avg / total       0.72      0.74      0.71       300\n",
      " \n",
      " ----------------\n",
      "Conf. Matrix \n",
      " [[196  17]\n",
      " [ 60  27]] \n",
      " ----------------\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto')\n",
    "svm.fit(X_train_iso,risk1)\n",
    "r_svm = svm.predict(X_test_iso)\n",
    "print(\"Accuracy Score\",accuracy_score(risk2,r_svm),\"\\n ----------------\")\n",
    "print(\"Classification Report\",classification_report(risk2,r_svm),\"\\n ----------------\")\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_svm),\"\\n ----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.7033333333333334 \n",
      " ----------------\n",
      "Classification Report              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.88      0.81       213\n",
      "          1       0.48      0.28      0.35        87\n",
      "\n",
      "avg / total       0.67      0.70      0.68       300\n",
      " \n",
      " ----------------\n",
      "Conf. Matrix \n",
      " [[187  26]\n",
      " [ 63  24]] \n",
      " ----------------\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(gamma='auto')\n",
    "svm.fit(X_train_pca,risk1)\n",
    "r_svm = svm.predict(X_test_pca)\n",
    "print(\"Accuracy Score\",accuracy_score(risk2,r_svm),\"\\n ----------------\")\n",
    "print(\"Classification Report\",classification_report(risk2,r_svm),\"\\n ----------------\")\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_svm),\"\\n ----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce size with embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               3100      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 13,402\n",
      "Trainable params: 13,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "M1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "M1.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_hidden_mlp_test = M1.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_hidden_mlp_train = M1.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 700 samples in 0.060s...\n",
      "[t-SNE] Computed neighbors for 700 samples in 0.027s...\n",
      "[t-SNE] Computed conditional probabilities for sample 700 / 700\n",
      "[t-SNE] Mean sigma: 0.011263\n",
      "[t-SNE] Computed conditional probabilities in 0.130s\n",
      "[t-SNE] Iteration 50: error = 47.0303612, gradient norm = 0.3292722 (50 iterations in 1.573s)\n",
      "[t-SNE] Iteration 100: error = 44.5664902, gradient norm = 0.3418933 (50 iterations in 1.594s)\n",
      "[t-SNE] Iteration 150: error = 43.9504318, gradient norm = 0.3220161 (50 iterations in 1.514s)\n",
      "[t-SNE] Iteration 200: error = 44.0260506, gradient norm = 0.3254810 (50 iterations in 1.539s)\n",
      "[t-SNE] Iteration 250: error = 43.7992172, gradient norm = 0.3216765 (50 iterations in 1.653s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 43.799217\n",
      "[t-SNE] Iteration 300: error = 0.2168154, gradient norm = 0.0015733 (50 iterations in 1.514s)\n",
      "[t-SNE] Iteration 350: error = 0.1555422, gradient norm = 0.0002697 (50 iterations in 1.511s)\n",
      "[t-SNE] Iteration 400: error = 0.1486366, gradient norm = 0.0001558 (50 iterations in 1.556s)\n",
      "[t-SNE] Iteration 450: error = 0.1449296, gradient norm = 0.0001268 (50 iterations in 1.657s)\n",
      "[t-SNE] Iteration 500: error = 0.1428352, gradient norm = 0.0001235 (50 iterations in 1.686s)\n",
      "[t-SNE] Iteration 550: error = 0.1416505, gradient norm = 0.0001094 (50 iterations in 1.533s)\n",
      "[t-SNE] Iteration 600: error = 0.1407952, gradient norm = 0.0000794 (50 iterations in 1.519s)\n",
      "[t-SNE] Iteration 650: error = 0.1403926, gradient norm = 0.0000698 (50 iterations in 1.465s)\n",
      "[t-SNE] Iteration 700: error = 0.1401630, gradient norm = 0.0000646 (50 iterations in 1.853s)\n",
      "[t-SNE] Iteration 750: error = 0.1400997, gradient norm = 0.0000623 (50 iterations in 1.654s)\n",
      "[t-SNE] Iteration 800: error = 0.1397134, gradient norm = 0.0000519 (50 iterations in 1.671s)\n",
      "[t-SNE] Iteration 850: error = 0.1396983, gradient norm = 0.0000706 (50 iterations in 1.571s)\n",
      "[t-SNE] Iteration 900: error = 0.1397293, gradient norm = 0.0000630 (50 iterations in 1.496s)\n",
      "[t-SNE] Iteration 950: error = 0.1396173, gradient norm = 0.0000522 (50 iterations in 1.492s)\n",
      "[t-SNE] Iteration 1000: error = 0.1393795, gradient norm = 0.0000585 (50 iterations in 1.483s)\n",
      "[t-SNE] Error after 1000 iterations: 0.139380\n"
     ]
    }
   ],
   "source": [
    "X_hidden_train_tsne = tsne.fit_transform(X_hidden_mlp_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 151 nearest neighbors...\n",
      "[t-SNE] Indexed 300 samples in 0.000s...\n",
      "[t-SNE] Computed neighbors for 300 samples in 0.164s...\n",
      "[t-SNE] Computed conditional probabilities for sample 300 / 300\n",
      "[t-SNE] Mean sigma: 2.144005\n",
      "[t-SNE] Computed conditional probabilities in 0.029s\n",
      "[t-SNE] Iteration 50: error = 59.4988060, gradient norm = 0.5027621 (50 iterations in 0.701s)\n",
      "[t-SNE] Iteration 100: error = 59.8181648, gradient norm = 0.5166724 (50 iterations in 0.712s)\n",
      "[t-SNE] Iteration 150: error = 61.3853340, gradient norm = 0.5075765 (50 iterations in 0.739s)\n",
      "[t-SNE] Iteration 200: error = 62.3165588, gradient norm = 0.5187105 (50 iterations in 0.734s)\n",
      "[t-SNE] Iteration 250: error = 62.0209045, gradient norm = 0.4940045 (50 iterations in 0.722s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 62.020905\n",
      "[t-SNE] Iteration 300: error = 1.0827872, gradient norm = 0.0039137 (50 iterations in 0.660s)\n",
      "[t-SNE] Iteration 350: error = 1.0205365, gradient norm = 0.0019032 (50 iterations in 0.621s)\n",
      "[t-SNE] Iteration 400: error = 0.9695733, gradient norm = 0.0011246 (50 iterations in 0.618s)\n",
      "[t-SNE] Iteration 450: error = 0.9408134, gradient norm = 0.0006856 (50 iterations in 0.623s)\n",
      "[t-SNE] Iteration 500: error = 0.9261875, gradient norm = 0.0006962 (50 iterations in 0.625s)\n",
      "[t-SNE] Iteration 550: error = 0.9172948, gradient norm = 0.0003532 (50 iterations in 0.623s)\n",
      "[t-SNE] Iteration 600: error = 0.9173065, gradient norm = 0.0001028 (50 iterations in 0.631s)\n",
      "[t-SNE] Iteration 650: error = 0.9167596, gradient norm = 0.0000949 (50 iterations in 0.637s)\n",
      "[t-SNE] Iteration 700: error = 0.9139000, gradient norm = 0.0010602 (50 iterations in 0.643s)\n",
      "[t-SNE] Iteration 750: error = 0.9133389, gradient norm = 0.0000868 (50 iterations in 0.634s)\n",
      "[t-SNE] Iteration 800: error = 0.9124406, gradient norm = 0.0001349 (50 iterations in 0.752s)\n",
      "[t-SNE] Iteration 850: error = 0.9123983, gradient norm = 0.0001295 (50 iterations in 0.628s)\n",
      "[t-SNE] Iteration 900: error = 0.9125140, gradient norm = 0.0000861 (50 iterations in 0.636s)\n",
      "[t-SNE] Iteration 950: error = 0.9125537, gradient norm = 0.0000823 (50 iterations in 0.626s)\n",
      "[t-SNE] Iteration 1000: error = 0.9123915, gradient norm = 0.0000745 (50 iterations in 0.651s)\n",
      "[t-SNE] Error after 1000 iterations: 0.912391\n"
     ]
    }
   ],
   "source": [
    "X_hidden_test_tsne = tsne.fit_transform(X_hidden_mlp_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "convex_hulls_tsne = exo4.convexHulls(X_hidden_tsne_test[:,:2], risk2)\n",
    "ellipses_tsne = exo4.best_ellipses(X_hidden_tsne_test[:,:2], risk2)\n",
    "nh_tsne = exo4.neighboring_hit(X_hidden_tsne_test[:,:2], risk2)\n",
    "\n",
    "visualization(X_hidden_tsne_test[:,:2], risk2, convex_hulls = convex_hulls_tsne, ellipses = ellipses_tsne,projname = 't-SNE', nh = nh_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=6)\n",
    "#neigh.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_transformed = hasher.fit_transform(X_hidden_mlp_test)\n",
    "pca = decomposition.TruncatedSVD(30) # Truncated\n",
    "X_red_test = pca.fit_transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=6, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.fit(X_red, risk1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_knn = neigh.predict(X_red_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score 0.6366666666666667 \n",
      " ----------------\n",
      "Classification Report \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.85      0.76       208\n",
      "          1       0.32      0.16      0.22        92\n",
      "\n",
      "avg / total       0.58      0.64      0.60       300\n",
      " \n",
      " ----------------\n",
      "Conf. Matrix \n",
      " [[176  32]\n",
      " [ 77  15]] \n",
      " ----------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy Score\",accuracy_score(risk2,r_knn),\"\\n ----------------\")\n",
    "print(\"Classification Report \\n\",classification_report(risk2,r_knn),\"\\n ----------------\")\n",
    "print(\"Conf. Matrix \\n\",confusion_matrix(risk2,r_knn),\"\\n ----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Anaconda3]",
   "language": "python",
   "name": "Python [Anaconda3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
